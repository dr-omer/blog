<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Activation function options for a neuron | My blog</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Activation function options for a neuron" />
<meta name="author" content="Omer" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In this post I am attempting to summarize the options available to modify the output of any given neuron." />
<meta property="og:description" content="In this post I am attempting to summarize the options available to modify the output of any given neuron." />
<link rel="canonical" href="https://dr-omer.github.io/blog/deeplearning/python/2020/07/25/activatation-function-neuron.html" />
<meta property="og:url" content="https://dr-omer.github.io/blog/deeplearning/python/2020/07/25/activatation-function-neuron.html" />
<meta property="og:site_name" content="My blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-25T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Omer"},"description":"In this post I am attempting to summarize the options available to modify the output of any given neuron.","@type":"BlogPosting","headline":"Activation function options for a neuron","dateModified":"2020-07-25T00:00:00-05:00","datePublished":"2020-07-25T00:00:00-05:00","url":"https://dr-omer.github.io/blog/deeplearning/python/2020/07/25/activatation-function-neuron.html","mainEntityOfPage":{"@type":"WebPage","@id":"https://dr-omer.github.io/blog/deeplearning/python/2020/07/25/activatation-function-neuron.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://dr-omer.github.io/blog/feed.xml" title="My blog" /><link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Activation function options for a neuron | My blog</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Activation function options for a neuron" />
<meta name="author" content="Omer" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In this post I am attempting to summarize the options available to modify the output of any given neuron." />
<meta property="og:description" content="In this post I am attempting to summarize the options available to modify the output of any given neuron." />
<link rel="canonical" href="https://dr-omer.github.io/blog/deeplearning/python/2020/07/25/activatation-function-neuron.html" />
<meta property="og:url" content="https://dr-omer.github.io/blog/deeplearning/python/2020/07/25/activatation-function-neuron.html" />
<meta property="og:site_name" content="My blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-25T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Omer"},"description":"In this post I am attempting to summarize the options available to modify the output of any given neuron.","@type":"BlogPosting","headline":"Activation function options for a neuron","dateModified":"2020-07-25T00:00:00-05:00","datePublished":"2020-07-25T00:00:00-05:00","url":"https://dr-omer.github.io/blog/deeplearning/python/2020/07/25/activatation-function-neuron.html","mainEntityOfPage":{"@type":"WebPage","@id":"https://dr-omer.github.io/blog/deeplearning/python/2020/07/25/activatation-function-neuron.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://dr-omer.github.io/blog/feed.xml" title="My blog" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">My blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Activation function options for a neuron</h1><p class="page-description">In this post I am attempting to summarize the options available to modify the output of any given neuron.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-07-25T00:00:00-05:00" itemprop="datePublished">
        Jul 25, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Omer</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#deeplearning">deeplearning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#python">python</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/dr-omer/blog/tree/master/_notebooks/2020-07-25-activatation-function-neuron.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          
          <div class="px-2">
    <a href="https://colab.research.google.com/github/dr-omer/blog/blob/master/_notebooks/2020-07-25-activatation-function-neuron.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#Activation-function">Activation function </a>
<ul>
<li class="toc-entry toc-h2"><a href="#Sigmoid-activation-Function">Sigmoid activation Function </a></li>
<li class="toc-entry toc-h2"><a href="#Tanh-activation-function">Tanh activation function </a></li>
<li class="toc-entry toc-h2"><a href="#ReLu-activation-function">ReLu activation function </a></li>
<li class="toc-entry toc-h2"><a href="#Softmax-activation-function">Softmax activation function </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-07-25-activatation-function-neuron.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse-hide</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">e</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Activation-function">
<a class="anchor" href="#Activation-function" aria-hidden="true"><span class="octicon octicon-link"></span></a>Activation function<a class="anchor-link" href="#Activation-function"> </a>
</h1>
<ul>
<li>defined as $a = \sigma(z)$</li>
<li>$\sigma(z)$ can be<ul>
<li>sigmoid</li>
<li>tanh</li>
<li>ReLu</li>
<li>Softmax</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sigmoid-activation-Function">
<a class="anchor" href="#Sigmoid-activation-Function" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sigmoid activation Function<a class="anchor-link" href="#Sigmoid-activation-Function"> </a>
</h2>
<ul>
<li>Small changes in input lead to small changes in output (activation)</li>
<li>exterem changes in input lead to extrem changes in output (activation)</li>
<li>activation output range [0 1]
\begin{equation*}
\sigma(z) = \frac{1}{1+e^{-z}}
\end{equation*}</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">e</span><span class="o">**-</span><span class="n">z</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Sigmoid with w.x+b = z = 0.0001: '</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">(</span><span class="mf">0.00001</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Sigmoid with w.x+b = z = 1000  : '</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">(</span><span class="mi">10000</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Sigmoid with w.x+b = z = -10   : '</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Sigmoid with w.x+b = z = -100  : '</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Sigmoid with w.x+b = z = -2    : '</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Sigmoid with w.x+b = z = 0.0001:  0.5000024999999999
Sigmoid with w.x+b = z = 1000  :  1.0
Sigmoid with w.x+b = z = -10   :  4.539786870243442e-05
Sigmoid with w.x+b = z = -100  :  3.7200759760208555e-44
Sigmoid with w.x+b = z = -2    :  0.11920292202211757
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tanh-activation-function">
<a class="anchor" href="#Tanh-activation-function" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tanh activation function<a class="anchor-link" href="#Tanh-activation-function"> </a>
</h2>
<ul>
<li>acitvation output range [-1 1]
\begin{equation*}
\sigma(z) = \frac{e^{z} - e^{-z}}{e^{z} + e^{-z}}
\end{equation*}</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">e</span><span class="o">**</span><span class="n">z</span> <span class="o">-</span> <span class="n">e</span><span class="o">**-</span><span class="n">z</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">e</span><span class="o">**</span><span class="n">z</span> <span class="o">+</span> <span class="n">e</span><span class="o">**-</span><span class="n">z</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Tanh with w.x+b = z = 0.0001: '</span><span class="p">,</span> <span class="n">tanh</span><span class="p">(</span><span class="mf">0.00001</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Tanh with w.x+b = z = 100   : '</span><span class="p">,</span> <span class="n">tanh</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Tanh with w.x+b = z = -10   : '</span><span class="p">,</span> <span class="n">tanh</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Tanh with w.x+b = z = -100  : '</span><span class="p">,</span> <span class="n">tanh</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Tanh with w.x+b = z = -2    : '</span><span class="p">,</span> <span class="n">tanh</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Tanh with w.x+b = z = 0.0001:  9.999999999621023e-06
Tanh with w.x+b = z = 100   :  1.0
Tanh with w.x+b = z = -10   :  -0.9999999958776926
Tanh with w.x+b = z = -100  :  -1.0
Tanh with w.x+b = z = -2    :  -0.964027580075817
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="ReLu-activation-function">
<a class="anchor" href="#ReLu-activation-function" aria-hidden="true"><span class="octicon octicon-link"></span></a>ReLu activation function<a class="anchor-link" href="#ReLu-activation-function"> </a>
</h2>
<ul>
<li>activation range [0 z] 
\begin{equation*}
a = \sigma(z) = max(0,z)
\end{equation*}</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">z</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'ReLu with w.x+b = z = 0.0001: '</span><span class="p">,</span> <span class="n">relu</span><span class="p">(</span><span class="mf">0.00001</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'ReLu with w.x+b = z = 100   : '</span><span class="p">,</span> <span class="n">relu</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'ReLu with w.x+b = z = -10   : '</span><span class="p">,</span> <span class="n">relu</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'ReLu with w.x+b = z = -100  : '</span><span class="p">,</span> <span class="n">relu</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'ReLu with w.x+b = z = -2    : '</span><span class="p">,</span> <span class="n">relu</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>ReLu with w.x+b = z = 0.0001:  1e-05
ReLu with w.x+b = z = 100   :  100
ReLu with w.x+b = z = -10   :  0
ReLu with w.x+b = z = -100  :  0
ReLu with w.x+b = z = -2    :  0
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Softmax-activation-function">
<a class="anchor" href="#Softmax-activation-function" aria-hidden="true"><span class="octicon octicon-link"></span></a>Softmax activation function<a class="anchor-link" href="#Softmax-activation-function"> </a>
</h2>
<ul>
<li>
<p>activation range</p>
</li>
<li>
<p>For single ouput neuron
\begin{equation*}
\sigma(z) = e^{z} ~~~~~~~~~~~~~~~~~~~~~~~(1)
\end{equation*}</p>
</li>
<li>
<p>Combining results over all $K$ output neurons; hence softmax (normalizing each $ith$ neuron by total $K$ neurons)</p>
</li>
</ul>
\begin{equation*}
\sigma(z)_{i} = \frac {e^{z_{i}}} {\sum_{j=1}^{K} e^{z_{j}}} ~~~~~~~~~~~~~~~~~~~~~~~(2)
\end{equation*}<p>for $i=1...K$</p>
<ul>
<li>In the end for selecting winning neuron we appy np.argmax()</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Code" data-close="Show Code"></summary>
        <p></p>
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#collapse-hide</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">exp</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

    </details>
</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">z</span><span class="p">):</span> <span class="c1"># concise defination using list comprehension of python</span>
    <span class="n">each_neuron</span> <span class="o">=</span> <span class="p">[</span><span class="n">exp</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">z</span> <span class="p">]</span> <span class="c1"># compute exp for each individual neuron (eq-1 above)</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">j</span><span class="o">/</span><span class="nb">sum</span><span class="p">(</span><span class="n">each_neuron</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">each_neuron</span><span class="p">]</span>  <span class="c1"># normalizing each neuron output by total (eq-2 above) </span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [-1,1,5]   : '</span><span class="p">,</span> <span class="n">softmax</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span> <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [0,2,1]    : '</span><span class="p">,</span> <span class="n">softmax</span><span class="p">([</span><span class="mi">0</span> <span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span> <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [-10,1,5]  : '</span><span class="p">,</span> <span class="n">softmax</span><span class="p">([</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [5,1,5]    : '</span><span class="p">,</span> <span class="n">softmax</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>  <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [3,5,0]    : '</span><span class="p">,</span> <span class="n">softmax</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>  <span class="p">,</span><span class="s1">'</span><span class="se">\n\n</span><span class="s1">'</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Softmax with argmax to select the winning neuro in output'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [-1,1,5]   : '</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">softmax</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span> <span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [0,2,1]    : '</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">softmax</span><span class="p">([</span><span class="mi">0</span> <span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span> <span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [-10,1,5]  : '</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">softmax</span><span class="p">([</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">])))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [5,1,5]    : '</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">softmax</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>  <span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [3,5,0]    : '</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">softmax</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>  <span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>SoftMax with w.x+b = z = [-1,1,5]   :  [0.0024282580295913376, 0.017942534803329194, 0.9796292071670795]
SoftMax with w.x+b = z = [0,2,1]    :  [0.09003057317038046, 0.6652409557748219, 0.24472847105479764]
SoftMax with w.x+b = z = [-10,1,5]  :  [3.0040020689707753e-07, 0.017986204559030366, 0.9820134950407627]
SoftMax with w.x+b = z = [5,1,5]    :  [0.4954626425778431, 0.009074714844313747, 0.4954626425778431]
SoftMax with w.x+b = z = [3,5,0]    :  [0.11849965453500957, 0.8756005950630876, 0.005899750401902781] 


Softmax with argmax to select the winning neuro in output
SoftMax with w.x+b = z = [-1,1,5]   :  2
SoftMax with w.x+b = z = [0,2,1]    :  1
SoftMax with w.x+b = z = [-10,1,5]  :  2
SoftMax with w.x+b = z = [5,1,5]    :  0
SoftMax with w.x+b = z = [3,5,0]    :  1
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [-1,1,5]   : '</span><span class="p">,</span> <span class="n">softmax_expansive</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span> <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [0,2,1]    : '</span><span class="p">,</span> <span class="n">softmax_expansive</span><span class="p">([</span><span class="mi">0</span> <span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span> <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [-10,1,5]  : '</span><span class="p">,</span> <span class="n">softmax_expansive</span><span class="p">([</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [5,1,5]    : '</span><span class="p">,</span> <span class="n">softmax_expansive</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>  <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [3,5,0]    : '</span><span class="p">,</span> <span class="n">softmax_expansive</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>  <span class="p">,</span><span class="s1">'</span><span class="se">\n\n</span><span class="s1">'</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Softmax with argmax to select the winning neuro in output'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [-1,1,5]   : '</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">softmax_expansive</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span> <span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [0,2,1]    : '</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">softmax_expansive</span><span class="p">([</span><span class="mi">0</span> <span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span> <span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [-10,1,5]  : '</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">softmax_expansive</span><span class="p">([</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">])))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [5,1,5]    : '</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">softmax_expansive</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>  <span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'SoftMax with w.x+b = z = [3,5,0]    : '</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">softmax_expansive</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>  <span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>SoftMax with w.x+b = z = [-1,1,5]   :  [0.00242826 0.01794253 0.97962921]
SoftMax with w.x+b = z = [0,2,1]    :  [0.09003057 0.66524096 0.24472847]
SoftMax with w.x+b = z = [-10,1,5]  :  [3.00400207e-07 1.79862046e-02 9.82013495e-01]
SoftMax with w.x+b = z = [5,1,5]    :  [0.49546264 0.00907471 0.49546264]
SoftMax with w.x+b = z = [3,5,0]    :  [0.11849965 0.8756006  0.00589975] 


Softmax with argmax to select the winning neuro in output
SoftMax with w.x+b = z = [-1,1,5]   :  2
SoftMax with w.x+b = z = [0,2,1]    :  1
SoftMax with w.x+b = z = [-10,1,5]  :  2
SoftMax with w.x+b = z = [5,1,5]    :  0
SoftMax with w.x+b = z = [3,5,0]    :  1
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="dr-omer/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/deeplearning/python/2020/07/25/activatation-function-neuron.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Powered by fastpages.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/dr-omer.github.io" title="dr-omer.github.io"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/SyedOmerGilani" title="SyedOmerGilani"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
